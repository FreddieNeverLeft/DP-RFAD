{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreddieNeverLeft/DP-RFAD/blob/main/DP-RFAD_JIT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGeY-Qz61iJO"
      },
      "source": [
        "# setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETZ1YWxfn_q2"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eAsNM11umxLz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42504c89-79ea-48c8-e062-bfd3ce1dc7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.7/79.7 KB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for neural-tangents (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.9/61.9 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from torch_optimizer) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.5.0->torch_optimizer) (4.5.0)\n",
            "Installing collected packages: pytorch-ranger, torch_optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0\n"
          ]
        }
      ],
      "source": [
        "import functools\n",
        "\n",
        "from jax.example_libraries import optimizers\n",
        "import jax\n",
        "import jax.config\n",
        "from jax.config import config as jax_config\n",
        "jax_config.update('jax_enable_x64', True) # for numerical stability, can disable if not an issue\n",
        "from jax import numpy as jnp\n",
        "from jax import scipy as sp\n",
        "from jax import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.config.experimental.set_visible_devices([], 'GPU')\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# ## Flax (NN in JAX)\n",
        "# try:\n",
        "#     import flax\n",
        "# except ModuleNotFoundError: # Install flax if missing\n",
        "#     !pip install --quiet flax\n",
        "#     import flax\n",
        "# from flax import linen as nn\n",
        "# from flax.training import train_state, checkpoints\n",
        "\n",
        "try: \n",
        "  import neural_tangents as nt\n",
        "except ModuleNotFoundError: # Install neural_tangents if missing\n",
        "  !pip install -q git+https://www.github.com/google/neural-tangents\n",
        "  import neural_tangents as nt\n",
        "from neural_tangents import stax\n",
        "\n",
        "# try:\n",
        "#   import haiku as hk\n",
        "# except ModuleNotFoundError: # Install neural_tangents if missing\n",
        "#   !pip install git+https://github.com/deepmind/dm-haiku\n",
        "#   import haiku as hk\n",
        "!pip install torch_optimizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/yolky/RFAD"
      ],
      "metadata": {
        "id": "IfiMeiipQu4c",
        "outputId": "625a85ba-83dd-436b-9b50-8f1f99bf0e7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RFAD'...\n",
            "remote: Enumerating objects: 33, done.\u001b[K\n",
            "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 33 (delta 5), reused 33 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (33/33), 7.77 MiB | 12.29 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 RFAD/run_distillation.py --dataset cifar10 --save_path path/to/directory/ --samples_per_class 10 --platt --learn_labels"
      ],
      "metadata": {
        "id": "-XpZh9w1QcMd",
        "outputId": "a2abab0b-925b-4ff8-b696-dc0c94a159c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n",
            "100% 170498071/170498071 [00:02<00:00, 78364157.70it/s]\n",
            "Extracting ./data/cifar-10-python.tar.gz to ./data/\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H0Ms0K4-Qqiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "kGeY-Qz61iJO",
        "w8yR-mNeoP4K"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}